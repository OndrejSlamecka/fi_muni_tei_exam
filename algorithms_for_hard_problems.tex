\section{Algoritmy pro těžké problémy}

\subsection{Úvod}
Algoritmy pro řešení výpočetně náročných problémů.

\subsubsection{Znenie otázky}
Algoritmy pro řešení výpočetně náročných problémů. Náhodnostní 
algoritmy Monte Carlo a Las Vegas; náhodné procházky; aproximační 
algoritmy a jejich potenciál; genetické algoritmy; 
kvantové algoritmy (Shorův faktorizační a Groverův vyhledávací algoritmus).

\subsubsection{Pojmy}
Rozhodovacie/otimalizačné problémy; deterministické techniky (pseudopolynomiálne
algoritmy, parametrizované algoritmy, exponenciálne algoritmy); 
náhodnostné algoritmy (STRCMP, MAX-SAT, MAX-CUT, randomized quicksort),
typy náhodnostných algoritmov (Las Vegas, one sided error Monte Carlo, 
double sided error Monte Carlo, neohraničené Monte Carlo), derandomizovaný 
MAX-SAT; náhodné prechádzky (Markovove modely), očakávaný počet krokov 
(pre konkrétne u,v/navštíviť všetky vrcholy), Coupon selection problem, 2-SAT,
Drunkard's walk, MC; aproximatívne algoritmy, aproximatívny pomer, 
$\delta/f(n)$ aproximácia, technika hladového výberu (vrcholové pokrytie,
výber centier), technika cenovej funkcie (pokrytie množín);
techniky dymanického programovania (knapsack, problém súčtov), lineárne programovanie
(problém batohu, pokrytie množín), účelová funkcia + podmienky, primárna/duálna
funkcia, simplexový algoritmus; genetické algoritmy, populácia, selekcia, kríženie,
mutácia, použitie; kvantové algoritmy, Qubit, superpozícia, Shorov/Groverov algoritmus

\subsection{Algoritmy všeobecne}
Nech $\Sigma_1$ a $\Sigma_2$ sú abecedy, $U \subseteq \Sigma_1^*$.
{\em Výpočetný problém} je definovaný ako úloha vypočítať
funkciu $U \to \Sigma_2^*$, pričom prvky $x \in U$ sa nazývajú 
{\em vstupnými inštanciami}. 

Špeciálne sa budeme venovať dvom typom problémov - rozhodovacím
a optimalizačným.

\begin{definition}[Rozhodovací problém]
	{\em Rozhodovací problém} je trojica $(L, U, \Sigma)$, kde 
	$\Sigma$ je abeceda, $L \subseteq U \subseteq \Sigma^*$.
	Algoritmus $A$ rieši rozhodovací problém, $(L, U, \Sigma)$,
	ak pre každé $x \in U$ platí
	\[
		A(x) = 
		\begin{cases}
			1 &\quad\text{ak } x \in L\\
			0 &\quad\text{ak } x \in U \setminus L
		\end{cases}
	\]
\end{definition}

\begin{definition}[Optimalizačný problém]
	{\em Optimalizačný problém} je definovaný ako šestica 
	$(\Sigma_I, \Sigma_O, L, \mathcal{M}, cena, ciel)$, kde 
	\begin{itemize}
		\item $\Sigma_I, \Sigma_O$ sú vstupná a výstupná abeceda,
		\item $L \subseteq \Sigma_I^*$ je množina vstupných inštancií,
		\item $\mathcal{M}: L \to 2^{\Sigma_O^*}$ je funkcia, ktorá vstupnej
		inštancii priradí množinu prípustných riešení,
		\item $cena$ je funkcia, ktorá dvojici $(u,x), x \in L, u \in \mathcal{M}(x)$
		priradí reálne číslo $cena(u,x)$,
		\item $ciel \in \{maximum, minimum\}$.
	\end{itemize}
	
	Pre vstupnú inštanciu $x \in L$ sa riešenie $y \in \mathcal{M}(x)$ nazýva {\em optimálnym},
	pokiaľ $cena(y,x) = ciel\{ cena(z,x) | z \in \mathcal{M}(x) \} = Opt_U(x)$.
	
	Algoritmus je {\em konzistentný} ak pre každý vstup vráti prípustné riešenie,
	navyše je {\em optimálny}, ak pre každý vstup vráti optimálne riešenie.
\end{definition}

Pre začiatok spomenieme niekoľko deterministických techník na riešenie týchto 
problémov.

\subsubsection{Pseudopolynomiálne algoritmy}
Celočíselné problémy sú také, kde vstupom je množina celých čísel. Ako $Max(x)$
značíme maximálne číslo z danej množiny, ako $|x|$ dĺžku vstupu (vyjadreného 
binárne s oddeľovačmi).

Pre funkciu $h$ definujeme $h$-zúženie problému tak, že problém obmedzíme
na vstupné inštancie také, že $Max(x) \leq h(|x|)$.

Pseudopolynomiálny algoritmus je taký, ktorý pre polynomiálnu funkciu $p$ 
beží v čase $Time_A(x) = p(|x|, Max(x))$.

Celočíselný problém $U$ sa nazýva silne NP-ťažký, pokiaľ existuje polynóm $h$
taký, že $h$-zúženie problému $U$ je NP-ťažký problém. Pokiaľ $P \neq NP$, tak 
pre silne NP-ťažký celočíselný problém neexistuje žiadny pseudopolynomiálny algoritmus.

\subsubsection{Parametrizované algoritmy}
Parametrizované algoritmy sú také, ktoré bežia v polynomiálnom čase
voči veľkosti vstupy, avšak môžu byť exponenciálne voči nejakému parametru vstupu.

Parametrizáciou problému je funkcia $P$, ktorá je polynomiálne vypočítateľná
a platí, že pre nekonečne veľa hodnôt $k \in \mathbb{N}$ je $k$-parametrizovaná
množina $Set_U(k)=\{ x \in U | P(x) = k \}$ konečná.

Parametrizovaný algoritmus potom musí bežať v čase 
$Time_A(x) \leq f(P(x))\cdot p(|x|)$.

\subsection{Náhodnostní algoritmy}

\subsubsection{Monte Carlo algoritmy}

Monte Carlo algoritmy mají povolenou chybu s~omezenou pravděpodobností
menší než $1/2$.

\begin{definition}
Pravděpodobnostní algoritmus $M$ pro $L$ nazveme {\em Monte Carlo s~dvoustrannou
chybou}, pokud počítá v~polynomiálním čase
a navíc
\begin{itemize}
    \item pro $x \in L$ platí $P(M(x) = 1) > 1/2$,
    \item pro $x \not \in L$ platí $P(M(x) = 1) < 1/2$.
\end{itemize}
\end{definition}

\begin{definition}
Pravděpodobnostní algoritmus $M$ pro $L$ nazveme {\em Monte Carlo s~jednostrannou
chybou}, který počítá v~polynomiálním čase
a navíc
\begin{itemize}
    \item pro $x \in L$ platí $P(M(x) = 1) > 1/2$,
    \item pro $x \not \in L$ platí $P(M(x) = 1) = 0$.
\end{itemize}
\end{definition}

%Třídu problémů řešitelných MC algoritmy s~dvoustrannou chybou nazýváme
%$\BPP$, třídu problémů řešitelných MC algoritmy s~jednostrannou chybou
%$\RP$.
%Z~definice vyplývá, že Monte Carlo algoritmus nejde konvertovat na Las Vegas algoritmus.
%Platí ale, že $\RP \cap \coRP = \ZPP$ (třída problémů řešitelných Las
%Vegas algoritmy).

\begin{example}
    Definujme problém {\em hledání a}, ve kterém je zadané pole, v~němž
    polovinu prvků tvoří písmena $a$ a polovinu písmena $b$. Úkolem je
    najít index nějakého $a$.

    Uvažme algoritmus, který se $k$-krát podívá na náhodný index v~poli,
    pokud je na něm $a$, vrátí tento index, jinak po $k$ opakování vrátí
    některý z~navštívených indexů (tedy jistě špatný).
    Tento algoritmus je zřejmě Monte Carlo.
\end{example}

Dalším příkladem Monte Carlo algoritmu je Kargerův algoritmus pro
hledání minimálního řezu (více v~sekci o grafových algoritmech).

Důležitým aspektem Monte Carlo algoritmů je možnost je {\em
amplifikovat}. Jelikož je pravděpodobnost chyby $p < 1/2$, s~$k$
opakováními je pravděpodobnost chyby $p^k$, tedy klesá velmi rychle.


\subsubsection{Las Vegas algoritmy}

Existujú dva druhy Las Vegas algoritmov: bez chybnej odpovede alebo
s možnou odpoveďou \verb|?|.

Las Vegas algoritmus pre každý vstup musí vrátiť správnu odpoveď.
Jeho kľúčovou charakteristikou je jeho očakávaná časová zložitosť.

Las Vegas algoritmy s možnou odpoveďou \verb|?| nikdy nevrátí špatný výsledek, ale
s~pravděpodobností menší než $1/2$ můžou
vrátit odpověď \verb|?|. 

Příkladem Las Vegas algoritmu, který nevrací
\verb|?| je QuickSort s~náhodnostní volbou pivotu.

\begin{example}
    Uvažme opět problém hledání $a$ jako v~příkladu výše.
    Nyní navrhneme algoritmus, který se podívá na náhodný index v~poli,
    pokud je na něm $a$, vrátí tento index, jinak se opakuje.
    Tento algoritmus je zřejmě Las Vegas.
\end{example}

\begin{example}
    Uvažujme problém, kde máme $X$, $Y$, a každý z nich má $10$ reťazcov
	$x_1, \ldots, x_10$, resp. $y_1, \ldots, y_10$. Problémom je zistiť,
	či existuje $j$ také, že $x_j = y_j$. Deterministický algoritmus 
	by potreboval komunikačnú zložitosť $n$, pretože jeden počítač
	by musel poslať všetky svoje slová druhému.
	
	Vytvorme náhodnostný algoritmus taký, že $X$~pošle počítaču~$Y$
	zahashované všetky svoje reťazce. $Y$ porovná obdržané hashe 
	s~hashmi svojich reťazcov. Ak sa žiadny pár hashov nezhoduje, 
	$Y$~vráti odpoveď \textsc{Nie}. Pokiaľ sa nejaký pár hashov
	zhoduje, $Y$~vyberie náhodný z~daných párov a pošle svoj odpovedajúci
	reťazec počítaču~$X$. $X$~porovná dané reťazce, pokiaľ sa rovnajú, 
	vráti \textsc{Áno}, ak nie, vráti \verb|?|.
	
	Tento algoritmus je zjavne Las Vegas algoritmus s~možnou chybou.
\end{example}

Každý Las Vegas algoritmus, který vrací \verb|?| lze převést na
algoritmus, který \verb|?| nevrací prostým opakováním výpočtu dokud
nevrátí výstup různý od \verb|?|.

%Třída Las Vegas algoritmů se označuje $\ZPP$ a platí
%$\ZPP = \RP \cap \coRP$.

\subsection{Náhodné procházky}

Prof. Gruska má v~IA062 přednášku na téma náhodných procházek.
Naneštěstí jeho slidy se zabývají spíše náhodnými procházkami obecně
a nejde z~nich vyčíst žádná rozumná aplikace pro řešení problémů.
Podíváme se na algoritmus simulovaného žíhaní (simulated annealing) --
nejčastěji používaný algoritmus na bázi náhodných procházek pro řešení
optimalizačních problémů.

Nejprve připomeneme algoritmus {\em lokálního hledání} (local search,
hill climbing), který v~každém stavu vybere náhodný sousední stav a
přejde do něj, pokud je lepší než současný -- to opakuje tak dlouho,
dokud existuje lepší sousední stav.

% http://what-when-how.com/artificial-intelligence/a-comparison-of-cooling-schedules-for-simulated-annealing-artificial-intelligence/


Pro vysvětlení algoritmu {\em simulovaného žíhání} uvažme fyzikální
systém. Naším cílem je dostat se v~systému z~libovolného iniciálního
stavu do stavu s~nejmenší možnou energií. Chceme algoritmus navrhnout
tak, aby do lepších stavů přecházel vždy, ale zároveň chceme umožnit,
aby s~nějakou pravděpodobností unikl z~možného lokálního minima.
Postupně však chceme tyto možnosti stoupání omezit, abychom
se ke konci vymezeného času dostoupali do lokálního minima.

\begin{algorithm}
\caption{Simulované žíhání}
\begin{algorithmic}[1]
\Function{SA}{$ $}
    \State $s = s_0$
    \For{$k = 1..k_{max}$}
        \State $T \gets $ temperature$(k / k_{max})$
        \State $s_{new} \gets $ random\_neighbour$(s)$
        \If{$P(E(s), E(s_{new}), T) \geq$ random$(0,1)$}
            \State $s \gets s_{new}$
        \EndIf
    \EndFor
    \State \Return $s$
\EndFunction
\end{algorithmic}
\end{algorithm}

Pravděpodobnost přechodu je určena funkcí $P($energie současného stavu,
energie nového stavu, teplota$)$, která se $P$ definuje typicky takto:
\[
    P(E(s), E(s_{new}), T) =
    \begin{cases}
        1 & \text{pokud } E(s_{new}) < E(s), \\
        e^{-(E(s_{new}) - E(s)) / T} & \text{jinak.}
    \end{cases}
\]
Motivace pro volbu této funkce má sice kořeny ve fyzikálních aplikacích,
v~obecném použití jde ale hlavně o funkci, která má vlastnosti, které
pro správný průběh heuristiky potřebujeme.

Heuristiku můžeme aplikovat na problém obchodního cestujícího. Stavy
jsou permutace měst. Funkce získání souseda může například prohodit
dvě města. Teplotu můžeme například v~každém kroku násobit nějakou mírou
zchlazení.

\begin{example}
	Majme nasledovný algoritmus na problém 2-SAT. Náhodne vyberme nejaké
	pridelenie hodnôt premenných. Dokým formula nie je splnená, náhodne 
	vyber jednu nesplnenú klauzulu, a jednej z~jej premenných zmeň priradenie
	pravdivostnej hodnoty. 
	
	Nech $s$ je také priradenie hodnôt premenným, že toto priradenie je riešením
	problému. Potom zmenou prevedenou v~iterácii nášho algoritmu sa tomuto priradeniu
	buď priblížime o~jednu hodnotu, alebo sa o~jednu hodnotu vzdialime.
	
	Majme lineárny graf s $n+1$ vrcholmi, kde $n$ je počet premenných vo~formule,
	tieto vrcholmi označme číslami $0, \ldots, n$. Označenie vrchola značí
	počet premenných, v~ktorých sa aktuálne priradenie líši od~$s$. Vrchol~$0$
	teda značí priradenie~$s$, vrchol~$n$ presne opačné.
	
	Algoritmus teda simuluje náhodnú prechádzku po tomto grafe, s~tým, že v~každej
	iterácii sa z~vrcholu~$0 < i < n$ s~pravdepodobnosťou $1/2$ presunie do vrcholu~$i-1$,
	a s~pravdepodobnosťou $1/2$ do vrcholu $i+1$. 
	
	Očakávaný čas dosiahnutia vrcholu~$0$ je $n^2$.
\end{example}

\subsection{Aproximační algoritmy}

Aproximační algoritmus pro nějaký problém vrátí řešení, které je nějaké
kvality v~porovnání s~optimálním řešením.
Pro problém $L$ a jeho vstup $x$ definujeme aproximativní poměr
algoritmu $A$ jako
\[
    R_A(x) = \max \big \{ \frac{Opt_A(x)}{cena(A(x))},
    \frac{cena(A(x))}{Opt_A(x)} \big \}
\]
Algoritmus $A$ nazveme $\delta$-aproximativní pro $L$ pro
nějaké $\delta > 1$ pokud $R_A(x) < \delta$ pro všechna $x \in L$.
$\delta$ nemusí být jen konstanta, ale může to být i funkce velikosti
vstupu.

\begin{example}[Problém vrcholového pokrytí]
Ukážeme, že následující hladový algoritmus je $2$-aproximativní.  Stačí
uvážit, že každá vybraná hrana musí mít alespoň jeden z~vrcholů
v~optimálním pokrytí. Algoritmus přidal vždy dva vrcholy. Nemůže jich
být tedy ve výsledku více než dvojnásobek od optima.
%Všimneme si, že žádné dvě hrany vybrané algoritmem nemají společný
%vrchol, proto $\frac{1}{2} \lvert T \rvert \leq Opt(G)$,
%tedy $\frac{ \lvert T \rvert }{Opt(G)} \leq 2$.

\begin{algorithm}
\caption{Hladový algoritmus pro vrcholové pokrytí}
\begin{algorithmic}[1]
\Function{GreedyVC}{$G = (V,E)$}
    \State $T \gets \emptyset$
    \While{$E \neq \emptyset$}
        \State $(u,v) \gets$ pick an edge from $E$
        \State $T \gets T \cup \{u,v\}$
        \State $E \gets \{ (x,y) \in E \mid x,y \not \in \{u, v\} \}$
            \Comment{$E$ without edges incident to $u,v$}
    \EndWhile
    \State \Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}
\end{example}

\begin{example}
    % https://www.cs.cmu.edu/~avrim/451f12/lectures/lect1106.pdf

    Problém množinového pokrytí. Mějme množinu $X$ o $n$ prvcích
    a $m$ podmnožin $S_i$. Úkolem je najít nejmenší soubor množin $S_i$,
    který ve sjednocení dá $X$.

    Odpovídající rozhodovací problém má jako součást vstupu $k$ a ptá
    se, zda lze $X$ pokrýt $k$ množinami. Problém je $\NP$-úplný.

    Navrhneme hladový algoritmus: Vyber z~$S_i$ množinu, která pokrývá
    nejvíce prvků, odstraň tyto prvky a opakuj dokud není pokryto.

    Dokážeme, že pokud optimální řešení používá $k$ množin, tento
    algoritmus použije nejvýše $k \ln n$.

    Z~existence optimálního řešení musí existovat množina pokrývající alespoň
    $1/k$ prvků. Právě tu přitom algoritmus vybere, takže po první
    iteraci zbývá pokrýt nejvýše $n(1 - 1/k)$ prvků.
    Opět musí být množina pokrývající alespoň $1/k$ zbytku prvků.
    Po $t$ kolech zbývá $n(1-1/k)^t$ prvků,
    což pro $t = k \ln n$ je $n(1-1/k)^{k \ln n} < n(1/e)^{\ln n} = 1$,
    takže algoritmus je hotov.
\end{example}

Další metody odvození aproximačních algoritmů jsou například pomocí
lokálního vyhledávání nebo lineárního programování.
V~kontextu státnic je však důkaz jejich korektnosti složité tvrzení.

\subsection{Genetické algoritmy}

Genetický algoritmus provádí iterace. Udržuje přitom populaci řešení,
každé z~nich je kódováno (nejčastěji posloupností 0 a 1). V iteraci se
vyhodnotí kvalita řešení (pomocí funkce dané s problémem či simulací)
a vyberou se ty lepší. Z~vybraných řešení se vytvoří nové křížením
(zkombinují se části kódů rodičů) a mutací (náhodné změny). Pokračuje se
na další iteraci.

Příklad: Hledání řetězce s nejvyšším počtem jedniček.

\subsection{Úvod do kvantových algoritmů}

% https://math.stackexchange.com/questions/1779194/what-is-bra-and-ket-notation-and-how-does-it-relate-to-hilbert-spaces
% https://ocw.mit.edu/courses/physics/8-05-quantum-physics-ii-fall-2013/lecture-notes/MIT8_05F13_Chap_04.pdf

Krátký, intuitivní a nepřesný! (Toto téma není v~žádném z~povinných
předmětů a na dostudování těsně před státnicemi to není úplně snadné.)

Vektor $v$ značíme $\ket{v}$ ({\em ket}
$v$). Je-li $x \in \mathbb{N}$, potom $\ket{x}$ značí vektor binární
reprezentace $x$. {\em Qubit} $\ket{\psi}$ je lineární kombinace
$\ket{\psi} = \alpha \ket{1} + \beta \ket{0}$, kde $\ket{0} =
\bigl[\begin{smallmatrix}
1\\
0
\end{smallmatrix}\bigr]$, $\ket{1} = \bigl[\begin{smallmatrix}
0\\
1
\end{smallmatrix}\bigr]$, $\alpha, \beta \in \mathbb{C}$,
$\lvert \alpha \rvert^2 + \lvert \beta \rvert^2 = 1$.

{\em Měření quibtu} $\ket{\psi}$ (s~$\alpha, \beta$ jako výše) je sampling,
kde $1$ je vrácena s pravděpodobností
$\lvert \alpha \rvert^2 = 1$
a $0$ je vrácena s pravděpodobností
$\lvert \beta \rvert^2 = 1$. Měříme-li více qubitů zároveň, pak získáme
binární reprezentaci přirozeného čísla.

\subsection{Shorův faktorizační algoritmus}

Mějme dané číslo $N$, které chceme faktorizovat na $N = pq$.
Číslo N musí být skutečně složené (ověříme testem prvočíselnosti)
a nesmí být mocninou prvočísla (pro všechna $k \leq \log N$ otestujeme,
že $\sqrt[k]{N}$ není celé číslo).

Díky předpokladům a důsledkem CRT má $N$ čtyři různé odmocniny modulo
$N$, dvě z~nich $1$, $-1$. Hledáme odmocninu $b$ různou od $1,-1$, díky
které faktorizujeme $N$. Číslo $b$ nalezneme skrze náhodné číslo $a$
a jeho periodu.

Algoritmus probíhá následovně:

\begin{enumerate}
    \item Vyber náhodně $a < N$.
    \item Pokud $gcd(a, N) \neq 1$ máme dělitele.
    \item Použijeme QFT pro nalezení periody $f(x) = a^x \bmod N$,
        tj. řádu $a$ v~$\mathbb{Z}_N^*$.
    \item Je-li $r$ liché nebo $a^{r/2} = -1 \bmod N$, začni znova.
    \item $gcd(a^{r/2} + 1, N)$ a $gcd(a^{r/2} - 1, N)$ jsou dělitelé $N$.
\end{enumerate}

Intuitivní popis QFT nabízí Scott Aaronson \\
\href{https://www.scottaaronson.com/blog/?p=208}{https://www.scottaaronson.com/blog/?p=208}

% https://www.scottaaronson.com/blog/?p=208
% https://www.quora.com/How-does-Shors-algorithm-work-in-laymans-terms

\subsection{Groverův vyhledávací algoritmus}

% https://www.quora.com/How-would-you-explain-Grovers-algorithm-to-a-professional-programmer
% https://qbnets.wordpress.com/2010/01/06/grovers-algorithm-for-dummies/
% https://people.cs.umass.edu/~strubell/doc/quantum_tutorial.pdf
% https://www.quora.com/What-is-a-laymans-explanation-of-why-Grovers-algorithm-works?share=

% best
% http://twistedoakstudios.com/blog/Post2644_grovers-quantum-search-algorithm
% https://cstheory.stackexchange.com/questions/38538/oracle-construction-for-grovers-algorithm

Mějme čísla v rozsahu $[0, N)$, $N \in \mathbb{N}$ a hledáme
$\bar x$, které splňuje $f(\bar x) = 1$, zatímco $f(x') = 0, x' \neq
\bar x$.

Na klasickém počítači je tento problém řešitelný pouze průchodem všech
čísel, tedy v~čase $\Theta(N)$.
Groverův algoritmus tento problém řeší v~čase $\mathcal{O}(\sqrt{N})$.

Číslo $N$ reprezentujeme $n = \log_2 N$ bity jako vektor
$\ket{b_1 b_2 \ldots b_n}$. Pokud máme vektor blízko vektoru
reprezentujícímu $x$, potom kvantový sampling nám vrátí s~vysokou
pravděpodobností právě $x$. Groverův algoritmus v~$\sqrt{N}$ krocích
posune počáteční superpozici $\frac{1}{\sqrt{N}} \sum_{x = 0}^{N-1}
\ket{x}$, ve které jsou všechny hodnoty stejně pravděpodobné,
do směru $\bar x$.

Každý krok Groverova algoritmu je implementován postupnou aplikací
kvantového orákula $\mathcal{O}$, které převrátí amplitudu u $\bar x$,
tedy provede
\[
    \ket{x} \stackrel{\mathcal{O}}{\to} (-1)^{f(x)} \ket{x}
\]
potom spočítá průměr amplitud a zrcadlí každou amplitudu okolo průměru.

V~každém kroku se tak všechny neřešení posunou blíže k~sobě a změnšují
se, zatímco správné řešení vyčnívá a víc a víc. Kvantové orákulum je
realizace funkce $f$ na kvantovém počítači -- nemůžeme jej použít přímo,
protože by to znamenalo čtení kvantového registru dříve, než je správná
pravděpodobnost pro nalezení řešení.
